0
0
0
2

 
r
a

 

M
8
2

 
 
]
n
a
-
a
t
a
d

.
s
c
i
s
y
h
p
[
 
 

1
v
7
8
0
3
0
0
0
/
s
c
i
s
y
h
p
:
v
i
X
r
a

XAFS spectroscopy. II. Statistical evaluations in the ï¬tting problems

Moscow State Engineering Physics Institute, 115409 Kashrskoe sh. 31, Moscow, Russia

K. V. Klementev

e-mail: klmn@htsc.mephi.ru

(December 2, 2013)

The problem of error analysis is addressed in stages beginning with the case of uncorrelated
parameters and proceeding to the Bayesian problem that takes into account all possible correla-
tions when a great deal of prior information about the accessible parametr space is available. The
formulas for the standard deviations and deviations with arbitrary conï¬dence levels are derived.
Underestimation of the errors of XAFS-function extraction is shown to be a source of unjustiï¬ed
optimistic errors of ï¬tting parameters. The applications of statistical Ï‡2- and F -tests to the ï¬tting
problems are also discussed.

61.10.Ht

I. INTRODUCTION

In the Open Letter to the XAFS Community [1] Young and Dent, the leaders of the UK XAFS User Group,
expressed their concern over the persistence of lingering common opinion that XAFS is a â€œsporting techniqueâ€ and it
is possible to obtain the â€œanswer you wantâ€. Some way out they see in a special attention to the publishing XAFS data
(ï¬rst of all, to XAFS spectra) and have formulated several recommendations for editors and referees. Undoubtedly,
in the matter of extraction of the real, not invented, information from XAFS experiments the quality of spectra is
of great importance. We see here another problem as well. Not having some necessary elements of XAFS analysis
(some values and the procedures for their determination), one has a quite natural desire to turn those values to
advantage. Principally we mean the inability of the standard methods to ï¬nd the errors of the atomic-like background
Âµ0. Traditionally, the noise is assigned to these errors. However, as was shown in Ref. [2], the noise is essentially lower
than the errors of the Âµ0 construction. Below, we will show that the underestimation of the errors of XAFS-function
extraction is a source of the unreasonable optimistic errors of ï¬tting parameters.

Practically all known programs for XAFS modeling [3] in some way calculate conï¬dence limits of ï¬tting parameters.
However, since there is no standardized technique for that and since most published XAFS works do not contain any
mention of methods for estimation of the errors of ï¬tting parameters, the accuracy of the XAFS results remains to
be ï¬eld for trickery.

In the present article we derive the expressions for the errors of ï¬tting parameters under diï¬€erent assumptions on
the degree of their correlation. Besides, the prior information about parameters is possible to take into account in the
framework of Bayesian approach. Moreover one can ï¬nd the most probable weight of the prior information relative
to the experimental information.

We also discuss the grounds and usage of the statistical tests. The special attention was focused on that where and

how one can embellish the results and artiï¬cially facilitate the statistical tests to be passed.

All methods and tests described in the paper are realized in the program viper [6].

II. ERRORS IN DETERMINATION OF FITTING PARAMETERS

Let for the experimental curve d deï¬ned on the mesh x1, . . . , xM there exists a model m that depends on N
parameters p. In XAFS ï¬tting problems as d may serve both Ï‡(k) (not weighted by kw) and Ï‡(r). The problem is
to ï¬nd the parameter vector Ë†p that gives the best coincidence of the experimental and model curves. Introduce the
ï¬gure of merit, the Ï‡2-statistics (do not confuse with the symbol of XAFS function):

Ï‡2 =

(di âˆ’ mi)2

Îµ2
i

,

M

Xi=1

(1)

where Îµi is the error of di. The variate Ï‡2 obeys the Ï‡2-distribution law with M âˆ’ N degrees of freedom. Of course, for
the given spectrum d and the given model m the value of Ï‡2 is fully determined; we call it â€œvariateâ€ bearing in mind
its possible dispersion under diï¬€erent possible realizations of the noise and the experimental errors of di extraction.

1

Often a preliminary processing (before ï¬tting) is needed: smoothing, ï¬ltration etc. Naturally, during the pre-
processing some part of the experimental information is lost, and on the variates Î¾i = (di âˆ’ mi)/Îµi additional
dependencies are imposed (before, they were bound solely by the model m). It is necessary to determine the number
of independent experimental points Nind. For the commonly used in XAFS spectroscopy Fourier ï¬ltering technique
the number of independent points is given by [4]:

Nind = 2âˆ†kâˆ†r/Ï€ + 2,

(2)

where âˆ†k = kmax âˆ’ kmin and âˆ†r = rmax âˆ’ rmin are the ranges in k- r-spaces used for the analysis, and rmin > 0. If
rmin = 0 then

Nind = 2âˆ†kâˆ†r/Ï€ + 1.

(3)

Instead of keeping in the sum (1) only Nind items which are equidistantly spaced on the grid x1, . . . , xM , it is more
convenient to introduce the scale factor Nind/M :

Ï‡2 =

Nind
M

(di âˆ’ mi)2

Îµ2
i

.

M

Xi=1

(4)

Now the variate Ï‡2 follows the Ï‡2-distribution with Nind âˆ’ N degrees of freedom. It can be easily veriï¬ed that with
the use of all available data (rmin = 0 and rmax = Ï€/2dk) the deï¬nition (4) turns into (1).

Let us now derive the expression for the posterior distribution for an arbitrary ï¬tting parameter pj:

where P (p|d) is the joint probability density function for all values p, and the integration is done over all pi6=j.
According to Bayes theorem,

P (pj|d) =Z Â·Â·Â· dpi6=j Â·Â·Â· P (p|d),

(5)

P (p|d) =

P (d|p)P (p)

P (d)

,

(6)

P (p) being the joint prior probability for all pi, P (d) is a normalization constant. Assuming that Nind values in d
are independent and normally distributed with zero expected values and the standard deviations Îµi, the probability
P (d|t), so-called likelihood function, is given by

where Ï‡2 was deï¬ned above by (4). Its expansion in terms of p near the minimum (âˆ‡pÏ‡2 = 0) which is reached at
p = Ë†p yilds:

P (d|p) âˆ exp(cid:0)âˆ’Ï‡2/2(cid:1) ,

(7)

P (d|p) âˆ exp(cid:16)âˆ’

1
4

â†”

(p âˆ’ Ë†p)T Â· H

Â· (p âˆ’ Ë†p)(cid:17) â‰¡(cid:16)âˆ’

1
4

N

Xk,l=1

âˆ‚2Ï‡2
âˆ‚pkâˆ‚pl

âˆ†pkâˆ†pl(cid:17),

(8)

â†”

where âˆ†pk = pk âˆ’ Ë†pk, and the Hessian H
â†”
at the minimum of Ï‡2. The suï¬ƒcient conditions for the minimum are H
Hence, the surfaces of constant level of P (d|p) are ellipsoids.

components (the second derivatives) are calculated in the ï¬tting program
2
kl > 0, for any k, l.

â†”
kk > 0 and H

â†”
kkH

â†”

ll âˆ’ H

A. Simplest cases

Let us consider here two widely used approaches.

If one ignores the prior then the posterior probability density function P (p|d) coincides with the likelihood P (d|p).
(a) Parameters are perfectly uncorrelated. In this case the Hessian is diagonal and

The standard deviation of pj is just

P (pj|d) âˆ exp(cid:16)âˆ’

1
4

2

â†”
H

jj âˆ†p2

j(cid:17).

(9)

(b) Parameter pj essentially correlates solely with pi. In this case

â†”
Î´(a)pj = (2/H

jj )1/2.

P (pj|d) âˆZ dpiP (pipj|d) âˆZ dpi exp(cid:16)âˆ’
iii (âˆ†pj)2(cid:17),

âˆ exp(cid:16)âˆ’

4hH

jj âˆ’ H

â†”
2
ij/H

1
4

â†”

â†”

1

from where one ï¬nds Â¯pj = Ë†pj and the mean-square deviation

â†”
jj (âˆ†pj)2 âˆ’
H

1
2

â†”
H
ijâˆ†pjâˆ†pi âˆ’

1
4

â†”
H

ii(âˆ†pi)2(cid:17)

Î´(b)pj = 

â†”
H

ii

â†”
2H
â†”
jjH
ii âˆ’ H

â†”

ij!1/2

2

.

In practice, to ï¬nd the strongly correlated pairs of parameters, one ï¬nds the pair-correlation coeï¬ƒcients:

rij = hâˆ†piâˆ†pji âˆ’ hâˆ†piihâˆ†pji

Î´(âˆ†pi)Î´(âˆ†pj)

taking on the values from -1 to 1. Two parameters are uncorrelated if their correlation coeï¬ƒcient is close to zero. It
is easy to calculate the average values over the distribution (11): hâˆ†p2
ii/Det, hâˆ†piâˆ†pji =
/2.
âˆ’2H
Now the pair-correlation coeï¬ƒcients are given by:

â†”
â†”
2
ij . Notice, by the way, that these are the elements of the inverse matrix of H

â†”
ij/Det, where Det = H

jj /Det, hâˆ†p2

ji = 2H

ii = 2H

ii âˆ’ H

â†”
jjH

â†”

â†”

â†”

Via the correlation coeï¬ƒcient the mean-square deviations, found for the cases (a) and (b), are simply related:

rij = âˆ’

.

â†”
iiH

jj

â†”
H
â†”

ij

qH

(10)

(11)

(12)

(13)

(14)

(15)

Î´(a)pj = Î´(b)pjq1 âˆ’ r2

ij .

Consider an example of the error analysis. For L3 Pb absorption spectrum1 for BaPbO3 compound the average error
of the XAFS extraction from the measured absorption was Îµi = 0.007. For the ï¬ltered over the range 1.0 < r < 2.1 ËšA
(the signal from the octahedral oxygen environment of lead atom) XAFS (see Fig. 1), the model function was calculated
as follows. For one-dimensional the Hamiltonian of the lead-oxygen atomic pair with potential U = a/2 Â· (r âˆ’ r0)2 we
found the energy levels and corresponding to them wave functions. Then, averaging over the Gibbs distribution, the
pair radial distribution function (PRDF) normalized to the coordination number N was found as:

g(r) = NXn

|Î¨n(r)|2eâˆ’En/kT.Xn

eâˆ’En/kT ,

N =Z g(r) dr,

and the XAFS function as:

Ï‡(k) =

1
k

F (k)

g(r) sin[2kr + Ï†(k)]/r2 dr.

rmax

Zrmin

(16)

(17)

The phase shift Ï†(k) and the scattering amplitude F (k) were calculated using feff6 program [5]. By variation of
the parameters r0, a, N (where N includes the factor S2
0 ), and E0, the shift of the origin for the wave number k, one
search for the best accordance between the model and experimental curves. Here for the ï¬tting, the viper program
was used which, in particular, calculates the Hessian of Ï‡2 (deï¬nd by (4) with Nind = 11.8) at the minimum. The
correlation coeï¬ƒcients are listed in the Table I.

1The spectrum was recorded at 50 K in transmission mode at D-21 line (XAS-13) of DCI (LURE,Orsay, France) at positron
beam energy 1.85 GeV and the average current âˆ¼ 250 mA. Energy step â€” 2 eV, counting time â€” 1 s. Energy resolution
of the double-crystal Si [311] monochromator (detuned to reject 50% of the incident signal in order to minimize harmonic
contamination) with a 0.4 mm slit was about 2â€“3 eV at 13 keV.

3







 ?








 

 
.














 
 
7
 

&









7 ?







05072039
24/0

 , 







FIG. 1. Experimental and model ï¬ltered
XAFS Ï‡(k) Â· k2 (ï¬rst coordination sphere)
for BaPbO3 (a) and the model potential with
corresponding PRDF and energy levels (b).



?


 
 
7
 






 - 


TABLE I. Pair-correlation coeï¬ƒcients rij for the example ï¬tting.

N
1

âˆ’0.286
0.092
0.041

a

âˆ’0.286

1

âˆ’0.044
0.048

r0
0.092
âˆ’0.044

1
0.727

N
a
r0
E0

E0
0.041
0.048
0.727
1

TABLE II. Mean values and mean-square deviations of the ï¬tting parameters. Î´p are the mean-square deviations calculated:
for perfectly uncorrelated parameters (a), trough the maximum pair correlations (b), from the bayesian technique without prior
information (maximum likelihood) (c), from the posterior probability that considers the most probable contribution of the prior
information. Sp are the sizes of the parameter space accessible for variation (Â± around the mean value).

p
N
a, K/ËšA2
r0, ËšA
E0, eV

Ë†p
4.05
2.28Â·105
2.1456
4.42

Î´(a)p
0.090
4.7Â·104
2.7Â·10âˆ’3
0.23

Î´(b)p
0.094
4.9Â·104
3.9Â·10âˆ’3
0.34

Î´(c)p
0.096
4.9Â·104
4.0Â·10âˆ’3
0.35

Sp
Ë†N
Ë†a
Ë†r0
10

Î´(d)p
0.070
6.2Â·103
3.6Â·10âˆ’3
0.21

We now turn our attention to the errors of ï¬tting parameters. In ignoring the correlations, the errors Î´(a)p are rather
small (see Table II). However, we know that the parameters r0 and E0 are highly correlated, and their real errors
must be larger. In the traditional XAFS-analysis two-dimensional contour maps have long been used [7] for estimates
of the correlation score and the error bars. Notice, that to do this requires, ï¬rst, the deï¬nition and determination of
the correct statistical function Ï‡2 (but not a proportionate to it), and, second, a criterion to choose the critical value
of Ï‡2 (depending on the chosen conï¬dence level).

For the most correlated pair, r0 and E0, ï¬nd the joint probability density function P (r0E0|d) using the Hessian

elements found at the minimum of the Ï‡2:

P (r0E0|d) âˆ exp(cid:16)âˆ’

1
4

â†”
r0r0(âˆ†r0)2 âˆ’
H

1
2

â†”
r0E0âˆ†r0âˆ†E0 âˆ’
H

1
4

â†”
H

E0E0(âˆ†E0)2(cid:17)

(18)

4







  

  

  

  
  


/ - 7
/ , 7

FIG. 2. The joint probability density function P (r0E0|d) calculated via the expansion (8) (solid lines) and using the exact
Ï‡2 function (on the right, dashed lines). Also shown the graphical interpretation of the mean-square deviations Î´(a)r0 and
Î´(b)r0 given by (10) and (12). The ellipse of the standard deviation is drawn by the thick line.

which is depicted in Fig. 2 as a surface graph and as a contour map. The ellipses of the equal probability are described
by:

â†”
H

â†”
r0r0(âˆ†r0)2 + 2H

â†”
r0E0 âˆ†r0âˆ†E0 + H

E0E0 (âˆ†E0)2 = 4Î».

(19)

In Fig. 2 they limit such areas that the probability for the random vector (r0,E0) to ï¬nd itself in them is equal to
â„“ = 1âˆ’eâˆ’Î» = 0.2, 0.6, 0.8, 0.9 and 0.95. By the thick line is drawn the ellipse corresponding to the standard deviation:
Î» = 1/2 and â„“ = 1 âˆ’ eâˆ’1/2 â‰ˆ 0.3935. For this ellipse the point of intersection with the line âˆ†E0 = 0 and the point
of maximum distance from the line âˆ†r0 = 0 give the standard mean-square deviations Î´(a)r0 and Î´(b)r0 that coincide
with the expressions (10) and (12). To ï¬nd the mean-square deviation Î´(b) for an arbitrary conï¬dence level â„“, one

should multiply the standard deviation by pâˆ’2 ln(1 âˆ’ â„“).

In Table II the errors in the column Î´(b)p were found as the largest errors among all those calculated from the pair
correlations. For the parameters N and a all pair correlations are weak, so their Î´(a) and Î´(b) are hardly diï¬€er. For
the parameters r0 and E0 these mean-square deviations diï¬€er remarkable.

Finally, we put the question, how much is rightful the expansion (8) for the likelihood function? In Fig. 2, on the
right, the dashed ellipses of equal probability are found for the exact Ï‡2 that was calculated by the viper program
as well. Mainly, just-noticeable diï¬€erence is caused by the realization of the ï¬tting algorithm or to be more precise,
by the values of the variations of the ï¬tting parameters which determine the accuracy of the minimum itself and the
accuracy of the derivatives at the minimum. Of course, this diï¬€erence can be neglected.

B. General case

Often, a particular ï¬tting parameter signiï¬cantly correlates not with a one, but with several other parameters
(in our example this is not so, but, for instance, the problem of approximation of the atomic-like background by
interpolation spline drawn through the varied knots [8,2] is that very case). Now, the consideration of the two-
dimensional probability density functions is not correct no more, one should search for the total joint posterior
probability P (p|d).
of the variation range of the parameter pk. Then the prior probability can be expressed as:

For that, ï¬rst of all, one is to ï¬nd the prior probability P (p). Let we approximately know in advance the size Sk

P (p|Î±) âˆ Î±N/2 exp(cid:16)âˆ’

Î±
2

N

Xk=1

âˆ†p2
k
S2

k (cid:17),

5

(20)

where the regularizer Î± speciï¬es the relative weight of the prior probability; at Î± = 0 there is no prior information,
at Î± â†’ âˆ the ï¬tting procedure gives nothing and the posterior distribution coincides with the prior one. In the
expression (20) Î± appears as a known value. Later, we apply the rules of probability theory to remove it from the
problem.

So, for the sought probability density functions we have:

P (pj|d, Î±) âˆZ Â·Â·Â· dpi6=j Â·Â·Â· Î±N/2 exp(cid:16)âˆ’

1
2

N

Xk,l=1

gklâˆ†pkâˆ†pl(cid:17),

where

gkl =

Î±
S2
k

Î´kl +

â†”
H
kl
2

.

Since there is no integral over pj, separate it from the other integration variables:

P (pj|d, Î±) âˆ Î±N/2 exp(cid:16)âˆ’

1
2

gjjâˆ†p2

j(cid:17)Z Â·Â·Â· dpi6=j Â·Â·Â· exp(cid:16)âˆ’

1
2

N

Xj

k,l=1

gklâˆ†pkâˆ†pl âˆ’ âˆ†pj

N

Xj

k=1

gkjâˆ†pk(cid:17),

(21)

(22)

(23)

Here, the symbol j near the summation signs denotes the absence of j-th item. Further, ï¬nd the eigenvalues Î»i
and corresponding eigenvectors ei of the matrix gkl in which the j-th row and column are deleted, and change the
variables:

N

bi =pÎ»i

Xj

k=1

âˆ†pkeik,

âˆ†pk =

N

Xj

i=1

bieikâˆšÎ»i

(i, k 6= j).

Using the properties of eigenvectors:

N

Xj

k=1

glkeik = Î»ieil,

N

Xj

k=1

elkeik = Î´li

(l, i 6= j),

one obtains:

P (pj|d, Î±) âˆ Î±N/2 exp(cid:16)âˆ’
âˆ Î±N/2 exp(cid:16)âˆ’

where new quantities were introduced:

1
2

1
2

j(cid:17)Z Â·Â·Â· dbl6=j Â·Â·Â· exp(cid:16)âˆ’
[gjj âˆ’ u2]âˆ†p2
j(cid:17),
[gjj âˆ’ u2]âˆ†p2

1
2

N

Xj

i=1

[bi + uiâˆ†pj]2(cid:17)

ui =

1
âˆšÎ»i

N

Xj

k=1

gkjeik,

u2 =

u2
i .

N

Xj

i=1

(24)

(25)

(26)

(27)

Thus, we have found the explicit expression for the posterior distribution of an arbitrary ï¬tting parameter. This is

a Gaussian distribution with the mean Â¯pj = Ë†pj and the standard deviation

Î´(c)pj = (gjj âˆ’ u2)âˆ’1/2.

(28)

The formulas (26)â€“(28) require to ï¬nd the eigenvalues and eigenvectors for the matrix of rank N âˆ’ 1 for each
parameter. Those formulas have merely a methodological value: the explicit expressions for posterior probabilities
enables one to ï¬nd the average of arbitrary function of pj. However, the standard deviations could be calculated
signiï¬cantly easier, having found the eigenvalues and eigenvectors for the matrix of rank N one time.

(Î´(c)pj)2 = R âˆ†p2

j P (pj|d, Î±)dpj
R P (pj|d, Î±)dpj

= R âˆ†p2

j exp(cid:16)âˆ’ 1
k,l=1 gklâˆ†pkâˆ†pl(cid:17)dp
2PN
k,l=1 gklâˆ†pkâˆ†pl(cid:17)dp
R exp(cid:16)âˆ’ 1
2PN

.

6

(29)

Analogously to what was done above, performing the diagonalization of gkl, one obtains:

(Î´(c)pj)2 = R db(cid:16)PN

i=1 bieij/âˆšÎ»i(cid:17)2
exp(cid:16)âˆ’ 1
2PN
i(cid:17)
R db exp(cid:16)âˆ’ 1
2PN

i=1 b2

i=1 b2

i(cid:17)

=

e2
ij
Î»i

,

N

Xi=1

(30)

where the eigenvalues (Î»i) and eigenvectors (ei) correspond to the full matrix gkl.

â†”
One can give another interpretation of the Î´(c)p-ï¬nding process. It is easy to verify that H

/2 and the covariance

matrix C of the vector p are mutually inverse. Therefore

â†”
(Î´(c)pj)2 = Cjj = 2(H

âˆ’1)jj ,

(31)

and the variate (p âˆ’ Ë†p)T Â· C âˆ’1 Â· (p âˆ’ Ë†p) = 1
Â· (p âˆ’ Ë†p) is Ï‡2-distributed with N degrees of freedom if p is
the N -dimensional normally distributed vector (by Eq. (26) this condition is met). The ellipsoid that determines the
standard deviation is:

2 (p âˆ’ Ë†p)T Â· H

â†”

â†”

(p âˆ’ Ë†p)T Â· H

Â· (p âˆ’ Ë†p) = N.

(32)

For an arbitrary conï¬dence level â„“, on the r.h.s. would be (Ï‡2
degrees of freedom. The error Î´(c)pk is equal to the half the ellipsoid size along the k-th axis.

N )â„“, the critical value of the Ï‡2-distribution with N

In our example ï¬tting, the errors found in the absence of any prior information (Î± = 0) from the formula (30) are
listed in Table II in the column Î´(c)p. Due to every one parameter correlates at the most with one other parameter,
all Î´(c)p are practically coincide with Î´(b)p. Generally, this may be not so.

Finally, let us ï¬nd the most probable value of Î±. Its posterior distribution is given by:

P (Î±|d) =Z dpP (Î±, p|d) =Z dpP (Î±)P (p|Î±, d).

Using a Jeï¬€reys prior P (Î±) = 1/Î± [9], one obtains for the posterior distribution:

P (Î±|d) âˆZ dpÎ±N/2âˆ’1 exp(cid:16)âˆ’

1
2

N

Xk,l=1

gklâˆ†pkâˆ†pl(cid:17) âˆ (Î»1 Â·Â·Â· Î»N )âˆ’1/2Î±N/2âˆ’1.

(33)

(34)

In our example we have set the variation range of the parameter pk to be equal to Sk = Â±Ë†pk (this means that
pk âˆˆ [0, 2Ë†pk]) for all parameters except for E0; since it varies near zero, we have chosen SE0 = Â±10 eV. For the
mentioned variation ranges, the distribution P (Î±|d) has its mode at Î± = 2.64 Â· 103 (see Fig. 3). The bayesian errors
found for this regularizer are listed in the column Î´(d)p of Table II. As a result, we have got the mean-square errors
that for some parameters are signiï¬cantly lower than even Î´(a)p. There is nothing surprising in that: any additional
information narrows the posterior distribution. If we would choose Sk to be less, Î´(d)pk would be yet lower. For
instance, XAFS is quite accurate in distance determination, and for many cases one can assume distances to be
known within Â±0.2 ËšA. In our case this leads to Î´(d)r0 = 3.4 Â· 10âˆ’3 ËšA.

,2



 
/
,
 
!

FIG. 3. The posterior distribution for the regularizer

Î± found from Eq. (34).







,





7

C. Important note

Having obtained the expressions (10), (12) and (30) for the errors of ï¬tting parameters, we are able now to draw
an important conclusion. If in the deï¬nition (4) one substitutes for Îµi the values that are smaller by a factor of Î²
than the real ones, the Ï‡2 and its Hessianâ€™s elements are exaggerated by a factor of Î²2, and from (10), (12) and (30)
follows that the errors of ï¬tting parameters are understated by a factor of Î²!

In the preceding paper [2] it was shown that the errors of the atomic-like absorption construction are essentially
larger than the experimental noise, and therefore it is the former that should determine the Îµi values. However,
these values are traditionally assumed to be equal to the noise, or one uses unjustiï¬ed approximations for them, also
understated (like 1/Îµ2

i = kw [10]). It is here where we see the main source of the groundless optimistic errors.

III. STATISTICAL TESTS IN FITTING PROBLEMS

A. Ï‡2-test

Introducing the statistical function Ï‡2, we assumed that it follows the Ï‡2 distribution with Î½ = M âˆ’ N degrees of
freedom. However for this would be really so, one should achieve a suï¬ƒcient ï¬tting quality. This â€œsuï¬ƒcient qualityâ€
could be deï¬ned as such that the variate (4) obeys the Ï‡2 distribution law, that is this variate does not fall within
the tail of this distribution. Strictly speaking, the following condition must be met:

Ï‡2 < (Ï‡2

Î½ )â„“,

(35)

where the critical value (Ï‡2
mately (for odd Î½) using the known formulas [11].

Î½)â„“ for the speciï¬ed signiï¬cance level â„“ may be calculated exactly (for even Î½) or approxi-

Notice, that the choice of the true Îµi here also plays a cardinal role. However, it is important here that one would
not use the overestimated values which facilitate to meet the requirement (35). As we have shown in [2], one could
obtain the overestimated Îµi, having assumed the Poisson destribution law for the detectors counts when the actual
association between the probability of a single count event and the radiation intensity is unknown.

Thus, the exaggerated values Îµi tell about a quality ï¬tting, but give the large errors of ï¬tting parameters. The
understated Îµi lead to the would-be small errors, but make diï¬ƒcult to pass the Ï‡2-test (i. e. to meet the condition
(35)). We are aware of many works the authors of which do not describe explicitly the evaluation process for the
errors of XAFS-function extraction and do not report their explicit values. However, by implication it is seen that Îµi
were chosen (not calculated!) as low as possible to scarcely (with â„“ = 0.9 âˆ’ 0.95) pass the Ï‡2-test; as a result, very
impressive errors of the structural parameters were obtained. In such approach no wander that the diï¬€erence of 0.01 ËšA
between the diï¬€raction data and the XAFS-result that was found within 0.002 ËšA was attributed to the â€œsuggested
presence of a small systematic errorâ€ [10].

Let there is a possibility to choose between two physical models depending on diï¬€erent numbers of parameters N1
and N2 (N2 > N1). Which one of them is more statistically important? For instance one wish to decide whether a
single coordination sphere is split into two.

B. F -test

Let for the two models the functions Ï‡2

2 obey the Ï‡2-distribution law with Î½1 = Nindâˆ’N1 and Î½2 = Nindâˆ’N2
degrees of freedom, correspondingly. From the linear regression problem (near the minimum of Ï‡2, the likelihood
function is expressed by (8) and is identical in form to that of the linear regression problem) it is known that the
value

1 and Ï‡2

f =

(Ï‡2

1 âˆ’ Ï‡2
2)/(Î½1 âˆ’ Î½2)
Ï‡2
2/Î½2

(36)

obeys the Fisherâ€™s F -distribution law with (Î½1 âˆ’ Î½2, Î½2) degrees of freedom if exactly r = Î½1 âˆ’ Î½2 parameters in the
second model are linearly dependent, that is if exist the r Ã— N2 matrix C of rank r and the vector c of the dimension
r such that Cp = c. In order for the linear restrictions on the second model parameters to be absent, the value f
should not follow the F -distribution, that is it should be greater than the critical value (FÎ½1âˆ’Î½2,Î½2 )â„“ for the speciï¬ed
signiï¬cance level â„“:

8







.









or

FIG. 4. On the choice between two diï¬€erent models on

statistical grounds. Cited from Ref. [12].

19070//,9,
24/0
24/0













 ?


f > (FÎ½1âˆ’Î½2,Î½2 )â„“

Ï‡2
2 < Ï‡2

1(cid:18)(FÎ½1âˆ’Î½2,Î½2)â„“

Î½1 âˆ’ Î½2

Î½2

+ 1(cid:19)âˆ’1

.

(37)

(38)

Notice, that the expression (38) means the absence of exactly r linear restrictions on the second model parameters.
Even if (38) is realized, the less number of linear dependencies are possible. If, for instance, the splitting of a single
coordination sphere into two does not contradict to the F -test (38), some of the parameters of these two spheres may
be dependent, but not all. This justiï¬es the introduction of a new sphere into the model XAFS function.

Thus, having speciï¬ed the signiï¬cance level â„“, one can answer the question â€œwhat decrease of Ï‡2 must be achieved
to increase the number of parameters from N1 to N2?â€ or, inside out, â€œwhat is the probability that the model 2 is
better than the model 1 at speciï¬ed (N1, Ï‡2

1) and (N2, Ï‡2
1/Ï‡2

2)?â€
2 appears, the actual values of Îµi become not important for

Notice, that since in the deï¬nition for f the ratio Ï‡2

the F -test (only if they all are taken equal to a single value).

Consider an example of the statistical tests in the ï¬tting problem. In Fig. 4 are shown the experimental curve
with Nind = 11.8 and two model curves with N1 = 4 and N2 = 7. The underlying physical models were described in
Ref. [12]; here only the number of parameters is of importance. Let us apply the statistical tests. Through the ï¬tting
procedure for the model 1 we have: Î½1 = 11 âˆ’ 4 = 7, Ï‡2
7)0.95, for the model 2: Î½2 = 11 âˆ’ 7 = 4,
4)0.95. That is the ï¬rst model does not pass the Ï‡2-test. Further, f = 2.89 = (F3,4)0.84, from
1 = 5.3 < 9.5 = (Ï‡2
Ï‡2
where with the probability of 84% we can assert that the model 2 is better than the model 1.

1 = 16.8 > 14.1 = (Ï‡2

In the XAFS analysis the F -test has long been in use [7]. However, the words substantiating the test are often
wrong. The authors of Refs. [10,13], for example, even claimed that the value f (36) must follow the F -distribution,
although then in Ref. [13] there appears a really correct inequality (38).

IV. CONCLUSION

The solution of the main task of the XAFS spectroscopy, determination of the structural parameters, becomes
worthless if the conï¬dence in this solution is unknown. Here we mean not only the conï¬dence in the obtained ï¬tting
parameters that is their mean-square deviations, but also the credence to the very methods of the error analysis. It
is excessive optimistic errors evaluations lead to the suspicious attitude to the XAFS results.

To improve the situation could the development of the reliable and well-grounded techniques that do not allow
one to treat the data in an arbitrary way. First of all, this is a technique for determination of the real errors of the
atomic-like absorption construction. Second, we regard as necessary to standardize the method for the correct taking
into account of all pair correlation between ï¬tting parameters. And third, (we have not raised this question here)
programs for scattering phase and amplitude calculations should report on the conï¬dence limits for the calculated
values, that is report how sensitive the calculated values are to the choice of the parameters of scattering potentials.

9

[1] N. A. Young, A. J. Dent, Open Letter to the XAFS Comunity. Maintaining and improving the quality of published XAFS

data: a view from the UK XAFS user group. J. Synchrotron Rad. 6, 799 (1999), (Proc. of Int. Conf. XAFS X).

[2] K. V. Klementev, XAFS analysis. I. Extracting the ï¬ne structure from the absorption spectra. The preceding article ,

(2000).

[3] Catalog of XAFS Analysis Programs, http://ixs.csrri.iit.edu/catalog/XAFS_Programs .
[4] E. A. Stern, Number of relevant independent points in x-ray-absorption ï¬ne-structure spectra. Phys. Rev. B 48(13), 9825â€“

9827 (1993).

[5] J. J. Rehr, J. Mustre de Leon, S. I. Zabinsky, R. C. Albers, Theoretical X-ray Absorption Fine Structure Standards. J. Am.

Chem. Soc. 113, 5135â€“5140 (1991).

[6] K. V. Klementev, VIPER for Windows (Visual Processing in EXAFS Researches),

freeware, http://www.crosswinds.net/~klmn/viper.html .

[7] R. W. Joyner, K. J. Martin, P. Meehan, Some applications of statistical tests in analysis of EXAFS and SEXAFS data.

J. Phys. C: Solid State Phys. 20, 4005â€“4012 (1987).

[8] M. Newville, P. LÂ¯Ä±viÂ¸nË‡s, Y. Yacoby, J. J. Rehr, E. A. Stern, Near-edge x-ray-absorption ï¬ne structure of Pb: A comparison

of theory and experiment. Phys. Rev. B 47(21), 14126â€“14131 (1993).

[9] H. Jeï¬€reys, Theory of Probability (Oxford University Press, London, 1939), later editions: 1948, 1961, 1983.

[10] A. Filipponi, A. Di Chicco, X-ray-absorption spectroscopy and n-body distribution functions in condensed matter. II. Data

analysis and applications. Phys. Rev. B 52, 15135â€“15149 (1995).

[11] Handbook of mathematical functions with formulas, graphs and mathematical tables, edited by M. Abramowitz, I. Stegun

(Applied mathematical series, 55, National bureau of standards, 1964).

[12] A. P. Menushenkov, K. V. Klementev, EXAFS indication of double-well potential for oxygen vibration in Ba1âˆ’xKxBiO3.

J. Phys.: Condens. Matter 12, (2000), (accepted).

[13] A. Michalowicz, K. Provost, S. Laruelle, A. Mimouni, F-test in EXAFS ï¬tting of structural models. J. Synchrotron Rad.

6, 233â€“235 (1999), (Proc. of Int. Conf. XAFS X).

10

